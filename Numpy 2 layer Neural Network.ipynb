{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The purpose of this notebook is to serve as a basic neural network in \n",
    "#numpy. The data comes from grokking deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1) #Necessary for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return (x > 0) * x #Relu activation function returns 0 or x\n",
    "\n",
    "def relu_deriv(x):\n",
    "    return x > 0 #Returns the derivative of relu, which is 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "#This is the dataset for predictions on walking or stopping\n",
    "streetlights = np.array([   [ 1, 0, 1],\n",
    "                            [ 0, 1, 1 ],\n",
    "                            [ 0, 0, 1 ],\n",
    "                            [ 1, 1, 1 ]]\n",
    "                       )\n",
    "#This is the outcome to predict ie walking or stopping\n",
    "walk_vs_stop = np.array([1,1,0,0]).T #T transposes the array\n",
    "print(walk_vs_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declare the learning rates and the size of the hidden layers\n",
    "alpha = 0.2\n",
    "hidden_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.16595599  0.44064899 -0.99977125 -0.39533485]\n",
      " [-0.70648822 -0.81532281 -0.62747958 -0.30887855]\n",
      " [-0.20646505  0.07763347 -0.16161097  0.370439  ]]\n",
      "\n",
      "[[-0.5910955 ]\n",
      " [ 0.75623487]\n",
      " [-0.94522481]\n",
      " [ 0.34093502]]\n"
     ]
    }
   ],
   "source": [
    "#initialize weight arrays for each of the two hidden layers\n",
    "#Random.random outputs an array of floats of the input array multiplied\n",
    "weights_0_1 = 2*np.random.random((3,hidden_size)) - 1\n",
    "weights_1_2 = 2*np.random.random((hidden_size,1)) - 1\n",
    "\n",
    "print(weights_0_1)\n",
    "print()\n",
    "print(weights_1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0.6342311598444467\n",
      "Error: 0.35838407676317513\n",
      "Error: 0.0830183113303298\n",
      "Error: 0.006467054957103705\n",
      "Error: 0.0003292669000750734\n",
      "Error: 1.5055622665134859e-05\n"
     ]
    }
   ],
   "source": [
    "#Train the network for 60 iterations\n",
    "for iteration in range(60):\n",
    "    layer_2_error = 0 #Start with no error in the second layer\n",
    "    for i in range(len(streetlights)): #for each input in streetlights\n",
    "        layer_0 = streetlights[i:i+1] #Layer 0 becomes a slice of streetlights\n",
    "        layer_1 = relu(np.dot(layer_0,weights_0_1)) #layer 1 becomes the activated product of the inputs * weights\n",
    "        layer_2 = np.dot(layer_1,weights_1_2) #layer 2 becomes the dot product of layer 1 and its weights\n",
    "        layer_2_error += np.sum((layer_2 - walk_vs_stop[i:i+1]) ** 2) #Add the squared error between the actual output and the known training data\n",
    "        layer_2_delta = (layer_2 - walk_vs_stop[i:i+1]) #Find the difference between layer 2's output and the expected output\n",
    "        layer_1_delta = layer_2_delta.dot(weights_1_2.T) * relu_deriv(layer_1) #Find the derivative of the relut function and multiply that by the dot product of layer 2's delta and the weights for layer 2\n",
    "        weights_1_2 -= alpha * layer_1.T.dot(layer_2_delta) #change the weights by the learning rate multiplied by the dot product of layer 1's output and layer 2's delta\n",
    "        weights_0_1 -= alpha * layer_0.T.dot(layer_1_delta) #Change the weights of the first layer by the input and layer 1's delta\n",
    "        \n",
    "    if(iteration % 10 == 9):\n",
    "        print(\"Error: \" + str(layer_2_error)) #track error progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
